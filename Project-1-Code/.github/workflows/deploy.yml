name: RouteClouds CI/CD Pipeline

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      EKS_CLUSTER_NAME: ${{ secrets.EKS_CLUSTER_NAME }}
      KUBE_NAMESPACE: ${{ secrets.KUBE_NAMESPACE }}
      DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Test Backend
        run: |
          cd backend
          npm ci
          npm run build
          # Add npm test when tests are available

      - name: Test Frontend
        run: |
          cd frontend
          npm ci
          npm run build
          # Add npm test when tests are available

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and Push Backend Image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: |
            awsfreetier30/routeclouds-backend:latest
            awsfreetier30/routeclouds-backend:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and Push Frontend Image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: |
            awsfreetier30/routeclouds-frontend:latest
            awsfreetier30/routeclouds-frontend:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.OIDC_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update K8s Manifests with New Image Tags
        run: |
          sed -i "s|image: awsfreetier30/routeclouds-backend:.*|image: awsfreetier30/routeclouds-backend:${{ github.sha }}|" k8s/backend.yaml
          sed -i "s|image: awsfreetier30/routeclouds-frontend:.*|image: awsfreetier30/routeclouds-frontend:${{ github.sha }}|" k8s/frontend.yaml
          sed -i "s|image: awsfreetier30/routeclouds-backend:.*|image: awsfreetier30/routeclouds-backend:${{ github.sha }}|" k8s/migration_job.yaml

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME

      - name: Deploy to EKS
        run: |
          kubectl apply -n $KUBE_NAMESPACE -f k8s/

      - name: Verify Rollout
        run: |
          kubectl rollout status deployment/backend -n $KUBE_NAMESPACE --timeout=300s
          kubectl rollout status deployment/frontend -n $KUBE_NAMESPACE --timeout=300s

      - name: Smoke Test
        run: |
          # Wait for services to be fully available
          sleep 60

          # Get the ALB endpoint
          ALB_ENDPOINT=$(kubectl get ingress -n $KUBE_NAMESPACE -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')

          # Test backend API
          echo "Testing backend API..."
          curl -f http://$ALB_ENDPOINT/api/hello || exit 1

          # Test frontend accessibility
          echo "Testing frontend..."
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://$ALB_ENDPOINT/login)
          if [ $HTTP_CODE -eq 200 ]; then
            echo "Frontend is accessible"
          else
            echo "Frontend test failed with HTTP code: $HTTP_CODE"
            exit 1
          fi

      - name: Rollback on Failure
        if: failure()
        run: |
          echo "Deployment failed, initiating rollback..."

          # Revert to the previous deployment
          kubectl rollout undo deployment/backend -n $KUBE_NAMESPACE
          kubectl rollout undo deployment/frontend -n $KUBE_NAMESPACE

          # Verify rollback status
          kubectl rollout status deployment/backend -n $KUBE_NAMESPACE --timeout=300s
          kubectl rollout status deployment/frontend -n $KUBE_NAMESPACE --timeout=300s

          echo "Rollback completed. Reverted to previous stable deployment."